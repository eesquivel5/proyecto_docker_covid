<img src="./images/GalileoLogo.jpg" width="500">

# Proyecto Final - Covid 19 Dashboard

### Integrantes
* Ram√≥n Alberto Escobar Madrid - 21001346
* Heansell Diosymar Tahay Mench√∫ - 20005256
* Edi Antonio Ordo√±ez Hern√°ndez - 9912628
* Tom√°s Ernesto Esquivel Ramos - 21004407



## App sobre Estad√≠sticas de Covid 19 üöÄ

<hr/>

## Estructura del proyecto üñ•Ô∏è

```
root
|
|____api
|    |  crud.py
|    |  database.py
|    |  main.py
|    |  models.py
|    |  schemas.py
|
|____config
|    |  airflow.cfg
|
|____dags
|    |covid_dag.py
|
|____data
|    |  files.csv
|
|____images
|    |  images.png
|
|____project
|    |  app.py
|
|____script
|    |  entrypoint.sh
|    |  schema.sql
|
|____.gitignore
|
|____docker-compose.yml
|
|____Dockerfile
|
|____Dockerfile.fastapi
|
|____Dockerfile.streamlite
|
|____README.md
|
|____requirements.txt
|
|____schema.sql      

```
## Comandos üìã

Para levantar el ambiente de docker, es necesario ejecutar los siguientes comandos:


```
- docker-compose build
- docker-compose up
```

O para bajar el ambiente, lo siguiente:

```
- docker-compose down
```

En caso solo se necesite un servicio, √∫nicamente se le tiene que agregar el nombre despu√©s de cada comando mencionado anteriormente, por ejemplo, para la API (fastapi), seria como lo siguiente:

```
- docker-compose build fastapi
- docker-compose up fastapi
- docker-compose down fastapi
```

<hr/>

## Pipeline Dag en Airflow üõ†Ô∏è

La carpeta llamada "data", dentro de la estructura del proyecto, tendr√° contenida los siguientes archivos csv:

- time_series_covid19_confirmed_global.csv
- time_series_covid19_deaths_global.csv
- time_series_covid19_recovered_global.csv

Estos mismos ser√°n cargados a una tabla que se llama `covid_values`, el cual su estructura se encuentra definida en el archivo `schema.sql`. Por lo que vara verificar su contenido se recomienda visualizar en un manejador de base de datos MySQL, con la siguiente configuraci√≥n:

```
server: localhost
user: admin
pass: admin123
```

La anterior configuraci√≥n puede modificarse en el archivo docker-compose.yml en el servicio `db`. 

Seguidamente, para acceder desde el ambiente local al servidor de airflow, se recomienda ubicar en el navegador la siguiente ruta:

```
localhost:8080
```

Y para validar que el servidor se haya levantado correctamente, una vez ingresado a la ruta anterior, se deber√° mostrar algo como lo siguiente:

![Airflow Dashboard](./images/airflow-dashboard.png)

Para realizar correr el Dag, es necesario que previo a ese paso, se creen algunas conexiones necesarias, por tanto ubicarse en la pesta√±a `admin` y `connections`, tal como lo siguiente:

![Airflow Dashboard](./images/admin-connection.png)

El cual aparecer√° la siguiente p√°gina:

![Airflow Dashboard](./images/page-connection.png)

Para ello ubicarse en la pesta√±a `create` y escribir la conexi√≥n de `fs_covid`, el cual ser√° necesario para que Airflow sepa donde el sensor configurado en el Dag deba leer los archivos a ser cargados en la base de datos:

![Airflow Dashboard](./images/create-connection.png)

De la misma forma, en la lista de connections ubicar la conexi√≥n `mysql_default` y editarla, o en su defecto crearla con los siguientes par√°metros:

![Airflow Dashboard](./images/mysql-connection.png)

De lo anterior se tomaron los siguientes par√°metros configurados en el servicio `db` que se encuentra en el archivo de `docker-compose.yml`, el cual el equivalente ser√≠a lo siguiente:

```
- Host <=> 'db'
- Schema <=> 'MYSQL_DATABASE'
- Login <=> 'MYSQL_USER'
- Password <=> 'MYSQL_PASSWORD'
- Port <=> 'PORT_DOCKER_SERVICE'
```

## Ejecuci√≥n del Dag üì¶

Posterior a los pasos realizados anteriormente, para activar el dag, es necesario copiar toda la carpeta "data" a la carpeta "monitor" de la estructura del proyecto, tal como lo siguiente:

![Airflow Dashboard](./images/copy-data.png)


Seguidamente, ubicarse en el m√≥dulo "Dags" del dashboard de Airflow y encender el Dag `covid_dag`, tal como lo siguiente:

![Airflow Dashboard](./images/dag.png)

Lo anterior deber√≠a activar el pipeline de activaci√≥n de preprocesamiento de la data e inserci√≥n, logrando que despu√©s de un tiempo se visualice lo siguiente:

![Airflow Dashboard](./images/on-dag.png)

## Streamlit Dashboard üìñ

### Mapa

El dashboard fue dise√±ado con Streamlit, por compatibilidad con la funcionalidad y utilizar Python en todo el desarrollo de la aplicaci√≥n.

Se creo un mapa que muestre por c√≥digo de colores de burbujas que muestra la totalidad de los casos, recuperaciones y muertes para una fecha dada y un pa√≠s determinado.

![Airflow Dashboard](./images/Mapas.png)

